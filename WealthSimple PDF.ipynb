{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7da63a-c651-4dfa-bf42-fce2e7e46b32",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e85c0a5-39e1-480b-bfa1-78767c367c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:\n",
      "    3.9.18 (main, Nov  2 2023, 17:01:24) \n",
      "[Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "Java version:\n",
      "    openjdk version \"15.0.2\" 2021-01-19\n",
      "OpenJDK Runtime Environment AdoptOpenJDK (build 15.0.2+7)\n",
      "OpenJDK 64-Bit Server VM AdoptOpenJDK (build 15.0.2+7, mixed mode, sharing)\n",
      "tabula-py version: 2.8.2\n",
      "platform: macOS-12.7.4-x86_64-i386-64bit\n",
      "uname:\n",
      "    uname_result(system='Darwin', node='Pro.local', release='21.6.0', version='Darwin Kernel Version 21.6.0: Wed Jan 31 21:08:42 PST 2024; root:xnu-8020.240.18.707.2~1/RELEASE_X86_64', machine='x86_64')\n",
      "linux_distribution: ('Darwin', '21.6.0', '')\n",
      "mac_ver: ('12.7.4', ('', '', ''), 'x86_64')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import tabula\n",
    "tabula.environment_info()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d636ef-1cc9-4323-8d43-3bd92d9f41e5",
   "metadata": {},
   "source": [
    "# PDF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b539c-a2a8-4825-a120-67efe5f42ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction class\n",
    "transaction = Transaction(\n",
    "\n",
    "# Updated PDFTableExtractor with Transaction output\n",
    "class PDFTableExtractor:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def extract_table(self, pdf_path):\n",
    "        pdf_nested_dict = {}\n",
    "        dfs = tabula.read_pdf(self.file_path, stream=True, pages=\"all\")\n",
    "        index_correction = 0\n",
    "        for index, df in enumerate(dfs):\n",
    "            if df.empty:\n",
    "                index_correction +=1\n",
    "            elif not df.empty:\n",
    "                pdf_nested_dict[index - index_correction] = df\n",
    "        # print(pdf_nested_dict)      \n",
    "        return pdf_nested_dict\n",
    "\n",
    "# Updated BankStatementPDFTableExtractor\n",
    "class BankStatementPDFTableExtractor(PDFTableExtractor):\n",
    "    def extract_table(self, pdf_path):\n",
    "        # Use Tabula to extract table from BankStatement PDF\n",
    "        # Determine the interpretation (e.g., based on some criteria)\n",
    "        interpretation = self.determine_interpretation(pdf_path)\n",
    "\n",
    "        # Extract table with dynamic column names based on interpretation\n",
    "        if interpretation == \"Interpretation1\":\n",
    "            return self.extract_table_interpretation_1(pdf_path)\n",
    "        elif interpretation == \"Interpretation2\":\n",
    "            return self.extract_table_interpretation_2(pdf_path)\n",
    "        # Add more conditions for other interpretations\n",
    "\n",
    "    def determine_interpretation(self, pdf_path):\n",
    "        # Add logic to determine the interpretation based on some criteria\n",
    "        return interpretation\n",
    "\n",
    "    def extract_table_interpretation_1(self, pdf_path):\n",
    "        # Add logic to extract table with column names for Interpretation1\n",
    "        raw_dataframe = extracted_dataframe_interpretation_1\n",
    "\n",
    "        # Convert raw DataFrame to a list of Transaction objects\n",
    "        transactions = self.convert_to_transactions(raw_dataframe)\n",
    "\n",
    "        return transactions\n",
    "\n",
    "    def extract_table_interpretation_2(self, pdf_path):\n",
    "        # Add logic to extract table with column names for Interpretation2\n",
    "        raw_dataframe = extracted_dataframe_interpretation_2\n",
    "\n",
    "        # Convert raw DataFrame to a list of Transaction objects\n",
    "        transactions = self.convert_to_transactions(raw_dataframe)\n",
    "\n",
    "        return transactions\n",
    "\n",
    "    def convert_to_transactions(self, raw_dataframe):\n",
    "        # Implement logic to convert raw DataFrame to a list of Transaction objects\n",
    "        transactions = []\n",
    "\n",
    "        for index, row in raw_dataframe.iterrows():\n",
    "            # Extract required fields\n",
    "            date = row['Date']\n",
    "            description = row['Description']\n",
    "            amount = row['Amount']\n",
    "\n",
    "            # Extract additional attributes if needed\n",
    "            additional_attributes = self.extract_additional_attributes(row)\n",
    "\n",
    "            # Create Transaction object\n",
    "            transaction = Transaction(date, description, amount, additional_attributes)\n",
    "\n",
    "            transactions.append(transaction)\n",
    "\n",
    "        return transactions\n",
    "\n",
    "    def extract_additional_attributes(self, row):\n",
    "        # Implement logic to extract additional attributes from the row\n",
    "        # Return a dictionary of additional attributes\n",
    "        additional_attributes = {}\n",
    "        # Add more logic as needed\n",
    "        return additional_attributes\n",
    "\n",
    "# Usage\n",
    "source = \"BankStatement\"\n",
    "pdf_path = \"path/to/bank_statement.pdf\"\n",
    "\n",
    "factory = PDFTableExtractorFactory()\n",
    "extractor = factory.create_extractor(source)\n",
    "transactions = extractor.extract_table(pdf_path)\n",
    "\n",
    "# Now you have a list of Transaction objects, each with a standardized structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359def7e-b7ef-494e-aabe-829d27a0aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c281660-c319-44dc-b387-dbe220dca395",
   "metadata": {},
   "source": [
    "# WealthSimple Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1e380-6c39-4afc-8140-23d65345a94a",
   "metadata": {},
   "source": [
    "## Get the transation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3de71-e81d-4db5-a75a-329743578619",
   "metadata": {},
   "source": [
    "### from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b48653a-ded4-469e-ac99-e36b7c305b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the directory\n",
    "celi_directory_path = 'data/WealthSimple/CELI/'\n",
    "cash_directory_path = 'data/WealthSimple/cash/'\n",
    "\n",
    "path_list = [celi_directory_path, cash_directory_path]\n",
    "# Get a list of file names in the directory\n",
    "file_name_dict = {'celi':{'path': 'data/WealthSimple/CELI/',\n",
    "                          'files':[] }, \n",
    "                  'cash':{'path': 'data/WealthSimple/cash/',\n",
    "                          'files':[] }, \n",
    "                 }\n",
    "# get the path of the files in the dictionary\n",
    "for k, data in file_name_dict.items():\n",
    "    for file in os.listdir(data['path']):\n",
    "        if file[-3:]==\"pdf\":\n",
    "            data['files'].append(file)\n",
    "        \n",
    "# file_name_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1368c0a-b5d0-42a2-9845-2c94a2470e49",
   "metadata": {},
   "source": [
    "### to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724f996e-096c-4a73-9f22-7046e98180d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    }
   ],
   "source": [
    "cash_col_name_list = [\"CREDIT\", \"DEBIT\", \"BALANCE\"]\n",
    "\n",
    "def sort_debit_credit(df):\n",
    "    credit_list = []\n",
    "    debit_list = []\n",
    "    for amount in df[\"AMOUNT\"]:\n",
    "        # print(amount[0])\n",
    "        if amount[0] !=\"$\":\n",
    "            credit_list.append(None)\n",
    "            debit_list.append(amount)\n",
    "        else:\n",
    "            credit_list.append(amount)\n",
    "            debit_list.append(None)\n",
    "    df[\"CREDIT\"] = credit_list\n",
    "    df[\"DEBIT\"] = debit_list\n",
    "    return df\n",
    "                    \n",
    "def clean_amount_col(cash_col_name_list, df):\n",
    "    caracter_list = [\"$\", \",\", '-']\n",
    "    for col_name in cash_col_name_list:\n",
    "        amount_list = []\n",
    "        for amount in df[col_name]:\n",
    "            if amount:\n",
    "                for caracter in caracter_list:\n",
    "                    amount = amount.replace(caracter, \"\")\n",
    "                try:\n",
    "                    amount = float(amount)\n",
    "                except:\n",
    "                    amount = float(amount[1:])\n",
    "            amount_list.append(amount)\n",
    "        df[col_name] = amount_list\n",
    "    return df\n",
    "\n",
    "def g(s):\n",
    "    df = pd.DataFrame([x.split() for x in s])\n",
    "    df.columns = ['date', 'transaction_code', 'description']\n",
    "    df['description'] = df['description'].apply(lambda x: ' '.join(x[2:]))\n",
    "    return df\n",
    "\n",
    "def extract_info_from_Activity_Current_period_col(Activity_Current_period_col, col_name_list):\n",
    "    data_list = []\n",
    "    for desc in Activity_Current_period_col:\n",
    "        date_operation_desc_list = desc.split()\n",
    "        data_list.append([date_operation_desc_list[0], \n",
    "                          date_operation_desc_list[1], \n",
    "                          \" \".join(date_operation_desc_list[2:])\n",
    "                         ])\n",
    "    df_right = pd.DataFrame(data_list, columns=col_name_list)\n",
    "    return df_right\n",
    "    \n",
    "def get_transaction_df(file_name_dict):\n",
    "    col_name = [\"DATE\", \"DESCRIPTION\", \"AMOUNT\", \"BALANCE\"]\n",
    "    num_row = 0\n",
    "    df_list = []\n",
    "    for filename in file_name_dict['cash'][\"files\"]:\n",
    "        file_path = file_name_dict['cash'][\"path\"] + filename\n",
    "        dfs = tabula.read_pdf(file_path, stream=True, pages=\"all\")\n",
    "        # print(f\"File : {filename} has {len(dfs)} dataframe \")\n",
    "        \n",
    "        for i, df in enumerate(dfs):\n",
    "            # print(f\"  df {i} as {len(df.columns)} columns\")\n",
    "            \n",
    "            if len(df.columns) == 4:\n",
    "                if df.columns.to_list() == ['Activity - Current period', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']:\n",
    "                    # format columns\n",
    "                    # all_col_name_list = [x for x in df.loc[0]]\n",
    "                    # col_name_list = all_col_name_list[0].split()\n",
    "                    # other_col_name_list = all_col_name_list[1:]\n",
    "                    # old_name_col = df.columns.to_list()[1:4]\n",
    "                    # df.rename(columns={x:y for x,y in zip(old_name_col, other_col_name_list)}, inplace=True)\n",
    "                    \n",
    "                    # df_copy = df[1:].copy()\n",
    "                    # df_copy.reset_index(inplace=True)\n",
    "                    # df_copy.drop(\"index\", axis=1, inplace=True)\n",
    "                    # # print(df_copy)\n",
    "                    \n",
    "                    # df_right = extract_info_from_Activity_Current_period_col(df_copy['Activity - Current period'], col_name_list)\n",
    "                    \n",
    "                    # joined_df = pd.concat([df_copy, df_right], axis=1)\n",
    "                    \n",
    "                    # print(joined_df)\n",
    "                    pass\n",
    "                else:\n",
    "                    # pass\n",
    "                    # print(df.head())\n",
    "                    col_name = [\"DATE\", \"DESCRIPTION\", \"AMOUNT\", \"BALANCE\"]\n",
    "                    values = df.columns.to_list()\n",
    "                    first = pd.DataFrame({k:[v] for k,v in zip(col_name, values)})\n",
    "                    df.columns = col_name\n",
    "                    stacked_df = pd.concat([first, df], axis=0, ignore_index=True)\n",
    "                    num_row += len(stacked_df)\n",
    "                    stacked_df[\"DATE\"] = pd.to_datetime(stacked_df[\"DATE\"], format='%Y-%m-%d')\n",
    "                    stacked_df = sort_debit_credit(stacked_df)\n",
    "                    stacked_df = clean_amount_col(cash_col_name_list, stacked_df)\n",
    "                    # print(stacked_df)\n",
    "                    df_list.append(stacked_df)\n",
    "        # print(\"----------------------------------\")\n",
    "    print(num_row)\n",
    "    df_all = pd.concat(df_list, axis=0)\n",
    "    df_all.reset_index(inplace=True)\n",
    "    df_all.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "transaction_df = get_transaction_df(file_name_dict)    \n",
    "# print(transaction_df)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcc992-4d9b-409a-be89-fda047f45330",
   "metadata": {},
   "source": [
    "## Look at the merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1a73c2-7dee-4201-adaf-f5a6f89ba0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adonis Anjou',\n",
       " 'Agence De Mobilite Dur',\n",
       " 'Bikini Village',\n",
       " 'Brunet Plus Anjou',\n",
       " 'Bulk Barn',\n",
       " 'Cashback received',\n",
       " 'Charcuterie De Tours (',\n",
       " 'Cinema Triomphe Inc.',\n",
       " 'Costco Wholesale W525',\n",
       " 'Couchetard',\n",
       " 'Deposit',\n",
       " 'Dollarama',\n",
       " 'Ferme Sarrazin',\n",
       " 'Grumpys Bar',\n",
       " 'Iga',\n",
       " 'Interest earned',\n",
       " 'Jean Coutu 045',\n",
       " 'Jean Coutu 267',\n",
       " 'Kim Phat',\n",
       " 'Kumamoto Ramen',\n",
       " \"L' Echoppe Des Fromage\",\n",
       " \"L'atelier Du Pain\",\n",
       " 'La Vignoble Le Cep Dar',\n",
       " 'Les Fraiches - Epiceri',\n",
       " 'Marche Notre Dame 2225',\n",
       " 'Marche St Jean Baptist',\n",
       " 'Marche Toit Rouge',\n",
       " 'Maxi',\n",
       " 'Maxi & Cie Repentigny',\n",
       " \"Mcdonald's\",\n",
       " 'Metro De La Rousselier',\n",
       " 'Metro Fogarty',\n",
       " 'Proxi Extra Orford',\n",
       " 'Quebecloisirs Place',\n",
       " 'Restaurant Le Boucan',\n",
       " 'Saq23001 Ste-Catherine',\n",
       " 'Saq23106carrefour De L',\n",
       " 'Spanel Crepes Et Gourm',\n",
       " 'Stm Loge Charlevoix N1',\n",
       " 'Stm Loge Honor Beaugra',\n",
       " 'Stm Loge Lionel Groulx',\n",
       " 'Stm Loge Radisson N101',\n",
       " 'Super C La Plaine 2598',\n",
       " 'Super C Pte Aux Trembl',\n",
       " 'Super C Repentigny',\n",
       " 'Supermarche J P V Plou',\n",
       " 'Suzy Shier',\n",
       " 'Tim Hortons',\n",
       " 'Tradition',\n",
       " 'Walmart']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_list = list(transaction_df[\"DESCRIPTION\"].sort_values().unique())\n",
    "merchant_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c038fd-009e-46a7-8274-d36f0a52a8b3",
   "metadata": {},
   "source": [
    "### Is there new merchant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd7cfd71-30ab-4af8-a81b-b3d00af67326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épicerie Variable 150.0\n",
      "['adonis', 'costco', 'super c', 'iga', 'kim phat', 'les fraiches', 'maxi', 'metro', 'foodhero', 'les fraiches', 'adonis', 'provigo', 'marche richelieu', 'miel morand', 'ferme la vraie vie', 'pasta and fumo', 'flashfood', 'capulus cafe mobile', 'monsieur cocktail', 'nespresso canada']\n",
      "Transport (electricité / parking / metro-bus) Variable 300.0\n",
      "['agence de mobilite durablmontreal', 'stm', 'le circuit electrique montreal', 'flo services quebec', 'esso', 'shell', 'petro canada', 'agence de mobilite dur', 'stm']\n",
      "vin Variable 120.0\n",
      "['norman hardie winery', 'saq', 'karlo estates', 'lcbo', 'parsons brewing', 'stock and row', 'hinterland wine', 'county cider picton', 'slake brewing picton', 'domaine darius hillier on', 'closson chase vineyard hillier on', 'redtail vineyard', 'rosehall run vineyards', \"aux p'tits bocaux\"]\n"
     ]
    }
   ],
   "source": [
    "from investment.models import Merchant, Budget\n",
    "\n",
    "for budget in Budget.objects.all():\n",
    "    if budget.unique_provider_keywords:\n",
    "        print(budget)\n",
    "        substrings = [x.lower().strip() for x in budget.unique_provider_keywords.split(\",\") ]\n",
    "        print(substrings)\n",
    "# epicerie = Budget.objects.get(spending_item_name='Épicerie')\n",
    "\n",
    "# keywords_list = epicerie.unique_provider_keywords.split(\",\") if epicerie.unique_provider_keywords else []\n",
    "\n",
    "# keywords_list = [x.lower() for x in keywords_list]\n",
    "\n",
    "# keywords_list\n",
    "# # existing_merchant_set =  {merchant.name for merchant in Merchant.objects.all()}\n",
    "\n",
    "# new_merchant_name_to_insert_list = [m for m in merchant_list if m not in existing_merchant_set]\n",
    "\n",
    "# new_merchant_name_to_insert_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba4ec7b-f727-4d03-9cba-8c473053e673",
   "metadata": {},
   "source": [
    "### Association mot clef -> catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a3c7f-ee97-408e-98e0-5a19b29511de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les budget items ont des substring qui permette d'associer des marchand\n",
    "\n",
    "categories = {\n",
    "    \"Épicerie\": [\"Adonis\", \"Costco\", \"Super C\", \"Iga\", \"Kim Phat\", \"Les Fraiches\", \"Maxi\", \"Metro\"],\n",
    "    \"Vêtements\": [\"Bikini Village\", \"Dollarama\", \"Suzy Shier\"],\n",
    "    \"Restaurants\": [\"Grumpys Bar\", \"Kumamoto Ramen\", \"Mcdonald's\", \"Restaurant Le Boucan\"],\n",
    "    \"Bars\": [\"Grumpys Bar\"],\n",
    "    \"Pharmacies\": [\"Brunet Plus Anjou\", \"Jean Coutu 045\", \"Jean Coutu 267\"],\n",
    "    \"Vin\": [\"Saq23001 Ste-Catherine\", \"Saq23106carrefour De L\", \"La Vignoble Le Cep Dar\" ],\n",
    "    \"Autres\": [\"Bulk Barn\", \"Cashback received\", \"Charcuterie De Tours\", \"Cinema Triomphe Inc.\", \"Deposit\", \"Ferme Sarrazin\", \"Interest earned\", \"L' Echoppe Des Fromage\", \"L'atelier Du Pain\", \"Marche Notre Dame 2225\", \"Marche St Jean Baptist\", \"Marche Toit Rouge\", \"Maxi & Cie Repentigny\", \"Proxi Extra Orford\", \"Quebecloisirs Place\", \"Spanel Crepes Et Gourm\", \"Supermarche J P V Plou\", \"Tradition\", \"Walmart\"],\n",
    "    \"Transport Collectif\": [\"Agence De Mobilite Dur\", \"Stm\"]  # Corrected key name and removed extra parenthesis\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ee7a6d3-13a4-4521-8b51-47465d1123a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adonis anjou': <Budget: Épicerie Variable 150.0>, 'agence de mobilite dur': <Budget: Transport (electricité / parking / metro-bus) Variable 300.0>, 'bikini village': None, 'brunet plus anjou': None, 'bulk barn': None, 'cashback received': None, 'charcuterie de tours (': None, 'cinema triomphe inc.': None, 'costco wholesale w525': <Budget: Épicerie Variable 150.0>, 'couchetard': None, 'deposit': None, 'dollarama': None, 'ferme sarrazin': None, 'grumpys bar': None, 'iga': <Budget: Épicerie Variable 150.0>, 'interest earned': None, 'jean coutu 045': None, 'jean coutu 267': None, 'kim phat': <Budget: Épicerie Variable 150.0>, 'kumamoto ramen': None, \"l' echoppe des fromage\": None, \"l'atelier du pain\": None, 'la vignoble le cep dar': None, 'les fraiches - epiceri': <Budget: Épicerie Variable 150.0>, 'marche notre dame 2225': None, 'marche st jean baptist': None, 'marche toit rouge': None, 'maxi': <Budget: Épicerie Variable 150.0>, 'maxi & cie repentigny': <Budget: Épicerie Variable 150.0>, \"mcdonald's\": None, 'metro de la rousselier': <Budget: Épicerie Variable 150.0>, 'metro fogarty': <Budget: Épicerie Variable 150.0>, 'proxi extra orford': None, 'quebecloisirs place': None, 'restaurant le boucan': None, 'saq23001 ste-catherine': <Budget: vin Variable 120.0>, 'saq23106carrefour de l': <Budget: vin Variable 120.0>, 'spanel crepes et gourm': None, 'stm loge charlevoix n1': <Budget: Transport (electricité / parking / metro-bus) Variable 300.0>, 'stm loge honor beaugra': <Budget: Transport (electricité / parking / metro-bus) Variable 300.0>, 'stm loge lionel groulx': <Budget: Transport (electricité / parking / metro-bus) Variable 300.0>, 'stm loge radisson n101': <Budget: Transport (electricité / parking / metro-bus) Variable 300.0>, 'super c la plaine 2598': <Budget: Épicerie Variable 150.0>, 'super c pte aux trembl': <Budget: Épicerie Variable 150.0>, 'super c repentigny': <Budget: Épicerie Variable 150.0>, 'supermarche j p v plou': None, 'suzy shier': None, 'tim hortons': None, 'tradition': None, 'walmart': None}\n"
     ]
    }
   ],
   "source": [
    "# def categorize_strings(dictionary, string_list):\n",
    "#     result = {}\n",
    "#     for string in string_list:\n",
    "#         category_found = None\n",
    "#         for category, substrings in dictionary.items():\n",
    "#             if any(sub in string for sub in substrings):\n",
    "#                 category_found = category\n",
    "#                 break\n",
    "#         result[string] = category_found\n",
    "#     return result\n",
    "\n",
    "# result = categorize_strings(categories, new_merchant_name_to_insert_list)\n",
    "\n",
    "def categorize_strings(Budget, string_list):\n",
    "    result = {}\n",
    "    string_list = [x.lower() for x in string_list]\n",
    "    for string in string_list:\n",
    "        category_found = None\n",
    "        for budget in Budget.objects.all():\n",
    "            if budget.unique_provider_keywords:\n",
    "                substrings = [x.lower().strip() for x in budget.unique_provider_keywords.split(\",\") ]\n",
    "                if any(sub in string for sub in substrings):\n",
    "                    category_found = budget\n",
    "                    break\n",
    "        result[string] = category_found\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "result = categorize_strings(Budget, merchant_list)\n",
    "print(result)\n",
    "\n",
    "# categorized_merchant = categorize_strings(categories, new_merchant_name_to_insert_list)\n",
    "# categorized_merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fc49b-879c-4749-9d2c-82c11c765309",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_count = dfs_staked[\"DESCRIPTION\"].value_counts()\n",
    "desc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19928e14-90f1-4870-b223-4ec7d8819abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfs_staked.groupby(\"DESCRIPTION\").agg({\n",
    "    \"DESCRIPTION\": 'count',  # Frequency count\n",
    "    'DEBIT': 'sum',    # Sum of 'col2' values\n",
    "    'CREDIT': 'sum'     # Sum of 'col3' values (assuming numerical)\n",
    "})\n",
    "result = result.rename(columns={'DESCRIPTION': 'Description'})\n",
    "# .sort_values(\"DESCRIPTION\", ascending=False)\n",
    "result.sort_values(\"Description\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4869589-b27a-496a-a0bb-90f950e65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = directory_path + data_list[0]\n",
    "for file_name, d in data_dict.items():\n",
    "    file_path = directory_path + file_name\n",
    "    if os.path.isfile(file_path):\n",
    "        print(\"is file\")\n",
    "        dfs = tabula.read_pdf(file_path, stream=True, pages=\"all\")\n",
    "        for index, df in enumerate(dfs):\n",
    "            print(\"*********\", index)\n",
    "            col = df.iloc[0].to_list()\n",
    "            df.columns = col\n",
    "            df = df[1:]\n",
    "            data_dict[file_name][index] = df\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6309a-6136-41bd-9009-a6df0f227a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb751b-bdd8-4ecb-ad2f-53806e7f07ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662fc17-ccd7-48ec-a876-40aa596b34bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8174cb2-1ef3-4259-9054-ae7c7bf615f5",
   "metadata": {},
   "source": [
    "## WealthSimple Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd2c1d-49e8-41cf-b1f1-00dcede735e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "dict_0 = {}\n",
    "dict_1 = {}\n",
    "dict_2 = {}\n",
    "col_1 = ['nan', 'nan', 'Market % of Market', 'Book', '% of Total Book']\n",
    "col_2 = ['nan', 'Symbol', 'Total Quantity', 'Segregated', 'Market', 'Market', 'Book']\n",
    "# list_of_col = \n",
    "market_value_list = []\n",
    "percentage_market_value_list = []\n",
    "for file_name, df_dict in data_dict.items():\n",
    "    print(\"____________\", file_name)\n",
    "    print(f\"there are {len(dfs)} Dataframes\")\n",
    "    for index, dfe in df_dict.items():\n",
    "        df = dfe.copy()\n",
    "        df_col = dfe.columns.to_list()\n",
    "        if 'Market % of Market' in df_col:\n",
    "            df = df.iloc[:,1: ]\n",
    "            df = df[1:]\n",
    "            df.dropna(inplace=True)\n",
    "            df.reset_index(inplace=True)\n",
    "            df.drop(\"index\", axis=1, inplace=True)\n",
    "            mv_pmv = df[\"Market % of Market\"].str.split()\n",
    "            # print(mv_pmv.to_list())\n",
    "            market_value_list = [pd.to_numeric(x[0].replace(\"$\", \"\").replace(\",\", \"\")) for x in mv_pmv.to_list()]\n",
    "            percentage_market_value_list = [pd.to_numeric(x[1])/100 for x in mv_pmv.to_list()]\n",
    "            df[\"Market Value\"] = market_value_list\n",
    "            df[\"% of Market Value\"] = percentage_market_value_list\n",
    "            df.drop(\"Market % of Market\", axis=1, inplace=True)\n",
    "            # df[\"Book\"] = pd.to_numeric(df[\"Book\"].replace(\"$\", \"\").replace(\",\", \"\")) \n",
    "            df[\"Book\"] = df[\"Book\"].str.replace(\"$\", \"\", regex=True)\n",
    "            df[\"Book\"] = pd.to_numeric(df[\"Book\"].str.replace(\",\", \"\", regex=True))\n",
    "            df.rename(columns={\"Book\": \"Book Value\", np.nan: \"Description\", \"% of Total Book\": \"% of Total Book Value\"}, inplace=True)\n",
    "            df[\"% of Total Book Value\"] = pd.to_numeric(df[\"% of Total Book Value\"]) / 100\n",
    "        elif 'Segregated' in df_col:\n",
    "            df.rename(columns={np.nan: df.iloc[1, 0], \n",
    "                   \"Segregated\": \"Segregated Quantity\",\n",
    "                  }, inplace=True)\n",
    "            df.dropna(inplace=True)\n",
    "            df.reset_index(inplace=True)\n",
    "            df.drop('index', axis=1, inplace=True)\n",
    "            df.columns = [\"Description\", \"Symbol\", \"Total Quantity\", \"Segregated Quantity\", \"Market Value\", \"Total Market Value\", \"Book Value\"]\n",
    "            for col in [\"Market Value\", \"Total Market Value\", \"Book Value\"]:\n",
    "                df[col] = df[col].str.replace(\",\", \"\", regex=True)\n",
    "                df[col] = df[col].str.replace(\"$\", \"\", regex=True)\n",
    "                df[col] = df[col].str.replace(\"CAD\", \"\", regex=True)\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "        elif 'Last Statement Cash Balance' in df_col:\n",
    "            # pass/\n",
    "#              les titres des colone ne sont que la répétitio de la ligne d'avant\n",
    "            # print(df.columns.to_list())\n",
    "            for k, v in df.iterrows():\n",
    "                index_list = v.index.to_list()\n",
    "                index_list.insert(3, \"___\")\n",
    "                row_list = v.to_list()\n",
    "                # print(\"index\", len(index_list))\n",
    "                filtered_row = [item for item in row_list if str(item).lower() != 'nan' and (not isinstance(item, float) or not np.isnan(item))]\n",
    "                # print(\"row\", len(row_list), filtered_row)\n",
    "        elif 'Index ETF' in df_col:\n",
    "            # pass\n",
    "            col_names = [\"Description\", \"Symbol\", \"Total Quantity\", \"Segregated Quantity\", \"Market Value\", \"Total Market Value\", \"Book Value\"]\n",
    "            df.columns = col_names\n",
    "            for col in [\"Market Value\", \"Total Market Value\", \"Book Value\"]:\n",
    "                df[col] = df[col].str.replace(\",\", \"\", regex=True)\n",
    "                df[col] = df[col].str.replace(\"$\", \"\", regex=True)\n",
    "                df[col] = df[col].str.replace(\"CAD\", \"\", regex=True)\n",
    "            print(df.dropna())\n",
    "        elif 'Charged ($)' in df_col:\n",
    "            pass\n",
    "        elif 'Segregated Quantity' in df_col:\n",
    "            pass\n",
    "        else:\n",
    "            print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96e59f-4f89-4876-a635-8d1b1d7c4ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66035ae-c6b5-482d-9d6c-5bf96b938ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cf7d8-2bbd-4024-8c90-98df764fd071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
